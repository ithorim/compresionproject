{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. H LDPC (Low-Density Parity-Check) Matrix Generation\n",
    "\n",
    "#### Theory:\n",
    "LDPC codes are a class of linear error-correcting codes, first introduced by Robert Gallager in 1962. They are characterized by a sparse parity-check matrix H, which contains mostly 0s and relatively few 1s. This sparsity is key to their excellent performance and efficient decoding.\n",
    "\n",
    "The parity-check matrix H defines the code. For a code of length n with k information bits, H is an (n-k) × n matrix. Each row of H represents a parity-check equation, and each column corresponds to a bit in the codeword.\n",
    "\n",
    "#### Implementation:\n",
    "\n",
    "Our implementation creates an LDPC matrix H with the following parameters:\n",
    "- n = 15 (total number of columns, representing the codeword length)\n",
    "- k = 6 (number of information bits)\n",
    "- wr = 5 (width of block in the first set of rows)\n",
    "- wc = 3 (number of rows in each set)\n",
    "\n",
    "The matrix H is constructed in three steps:\n",
    "\n",
    "1. First Set of Rows:\n",
    "   We fill the first wc (3) rows with blocks of wr (5) ones. This creates a structured start to our matrix, ensuring a minimum number of checks for each bit.\n",
    "\n",
    "2. Second Set of Rows:\n",
    "   For each column, we randomly place a 1 in one of the next wc rows. This adds randomness to our matrix while maintaining its low density.\n",
    "\n",
    "3. Third Set of Rows:\n",
    "   Similar to the second set, we place another 1 in each column, but in the last wc rows. This ensures that each bit is checked by at least two parity equations.\n",
    "\n",
    "#### Code Explanation:\n",
    "\n",
    "- We use numpy to create and manipulate our matrix efficiently.\n",
    "- random.seed() is used to ensure reproducibility of our random placements.\n",
    "- The matrix is initialized with zeros and then filled according to our scheme.\n",
    "- We use nested loops and array slicing to efficiently place our 1s in the matrix.\n",
    "\n",
    "This construction method ensures that:\n",
    "1. The matrix is sparse (low-density).\n",
    "2. Each bit is involved in multiple parity checks.\n",
    "3. The checks are well-distributed across the bits.\n",
    "4. There's a balance between structure and randomness in the code.\n",
    "\n",
    "The resulting H matrix defines our LDPC code, which we'll use for encoding, decoding, and error correction in subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set the random seed to your index number\n",
    "random.seed(82, 2018)\n",
    "\n",
    "# Define parameters\n",
    "n = 15  # Total number of columns in matrix H\n",
    "k = 6   # Number of information bits (n - k = 9)\n",
    "wr = 5  # Width of block (columns) in the first set of rows\n",
    "wc = 3  # Number of rows in each set\n",
    "\n",
    "# Initialize H matrix with zeros\n",
    "H = np.zeros((n - k, n), dtype=int)\n",
    "\n",
    "# Fill the first set of rows\n",
    "for i in range(wc):\n",
    "    start_col = i * wr\n",
    "    end_col = start_col + wr\n",
    "    H[i, start_col:end_col] = 1\n",
    "\n",
    "# Fill the second set of rows\n",
    "for j in range(n):\n",
    "    row_index = random.randint(wc, 2*wc - 1)\n",
    "    H[row_index, j] = 1\n",
    "\n",
    "# Fill the third set of rows\n",
    "for j in range(n):\n",
    "    row_index = random.randint(2*wc, 3*wc - 1)\n",
    "    H[row_index, j] = 1\n",
    "\n",
    "print(\"LDPC Matrix H:\")\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generating Syndrome Table and Code Distance\n",
    "\n",
    "#### Theory:\n",
    "\n",
    "1. Syndrome Table:\n",
    "   In error-correcting codes, a syndrome is a pattern that identifies the presence and location of errors. The syndrome table maps each possible error pattern to its corresponding syndrome. This table is crucial for decoding received messages and correcting errors.\n",
    "\n",
    "   For an LDPC code with parity-check matrix H, the syndrome s of a received vector r is calculated as:\n",
    "   s = H * r (mod 2)\n",
    "\n",
    "   If s = 0, the received vector is a valid codeword. Otherwise, s indicates the presence of errors.\n",
    "\n",
    "2. Code Distance:\n",
    "   The code distance, often denoted as d_min, is the minimum Hamming distance between any two distinct codewords. In linear codes like LDPC, this is equivalent to the minimum weight of any non-zero codeword. The code distance is a key parameter that determines the error-correcting capability of the code.\n",
    "\n",
    "#### Implementation:\n",
    "\n",
    "Our implementation includes the following key functions:\n",
    "\n",
    "1. `generate_error_patterns(n)`:\n",
    "   - Generates all possible error patterns of length n, excluding the all-zero pattern.\n",
    "   - Uses binary representation to efficiently create these patterns.\n",
    "\n",
    "2. `calculate_syndrome(H, error)`:\n",
    "   - Calculates the syndrome for a given error pattern using matrix multiplication.\n",
    "\n",
    "3. `generate_syndrome_table(H)`:\n",
    "   - Creates a dictionary mapping syndromes to their corresponding error patterns.\n",
    "   - Only keeps the first occurrence of each syndrome, which corresponds to the lowest-weight error pattern for that syndrome.\n",
    "\n",
    "4. `determine_code_distance(H)`:\n",
    "   - Finds the minimum weight of a non-zero codeword by checking linear combinations of columns in H.\n",
    "   - Starts from weight 1 and increases until a valid codeword is found.\n",
    "\n",
    "#### Code Explanation:\n",
    "\n",
    "- We use itertools.combinations to efficiently generate error patterns of increasing weight.\n",
    "- The syndrome table is stored as a dictionary for quick lookup during decoding.\n",
    "- We use numpy's matrix operations for efficient syndrome calculation.\n",
    "- The code distance calculation checks all possible combinations of columns, which can be computationally intensive for large codes but is exact.\n",
    "\n",
    "#### Significance:\n",
    "\n",
    "1. The syndrome table is essential for efficient decoding. It allows us to quickly identify the most likely error pattern given a received syndrome.\n",
    "\n",
    "2. The code distance gives us an upper bound on the number of errors the code can correct. A code with distance d can correct up to ⌊(d-1)/2⌋ errors.\n",
    "\n",
    "3. These calculations provide insights into the error-correcting capabilities and performance of our LDPC code.\n",
    "\n",
    "By generating the syndrome table and calculating the code distance, we've laid the groundwork for error correction and gained important information about the strength of our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all possible error patterns\n",
    "def generate_error_patterns(n):\n",
    "    return [np.array(list(format(i, f'0{n}b')), dtype=int) for i in range(1, 2**n)]\n",
    "\n",
    "# Calculate syndrome for a given error pattern\n",
    "def calculate_syndrome(H, error):\n",
    "    return np.mod(H @ error, 2)\n",
    "\n",
    "# Generate syndrome and corrector table\n",
    "def generate_syndrome_table(H):\n",
    "    n = H.shape[1]\n",
    "    syndrome_table = {}\n",
    "    error_patterns = generate_error_patterns(n)\n",
    "    \n",
    "    for error in error_patterns:\n",
    "        syndrome = tuple(calculate_syndrome(H, error))\n",
    "        if syndrome not in syndrome_table:\n",
    "            syndrome_table[syndrome] = error\n",
    "    \n",
    "    return syndrome_table\n",
    "\n",
    "# Determine code distance\n",
    "def determine_code_distance(H):\n",
    "    n = H.shape[1]\n",
    "    for weight in range(1, n + 1):\n",
    "        for columns in itertools.combinations(range(n), weight):\n",
    "            if np.sum(np.mod(np.sum(H[:, columns], axis=1), 2)) == 0:\n",
    "                return weight\n",
    "    return n\n",
    "\n",
    "# Generate syndrome table\n",
    "syndrome_table = generate_syndrome_table(H)\n",
    "\n",
    "# Determine code distance\n",
    "import itertools\n",
    "code_distance = determine_code_distance(H)\n",
    "\n",
    "print(\"Syndrome Table:\")\n",
    "print(\"Corrector:           Syndrome:\")\n",
    "for syndrome, corrector in syndrome_table.items():\n",
    "    print(f\"{corrector} : {syndrome}\")\n",
    "\n",
    "print(f\"\\nCode Distance: {code_distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Gallager B Algorithm\n",
    "\n",
    "#### Theory:\n",
    "\n",
    "The Gallager B algorithm is a hard-decision decoding algorithm for LDPC codes, introduced by Robert Gallager in his seminal work on LDPC codes. It's an iterative decoding method that uses message passing between variable nodes (bits) and check nodes (parity checks) in the Tanner graph representation of the code.\n",
    "\n",
    "Key features of Gallager B:\n",
    "1. It uses binary messages (0 or 1) between nodes.\n",
    "2. It employs threshold-based decision rules for updating bit values.\n",
    "3. It's relatively simple to implement but can be quite effective for LDPC decoding.\n",
    "\n",
    "#### Algorithm Steps:\n",
    "\n",
    "1. Initialize all variable nodes with the received bit values.\n",
    "2. For each iteration:\n",
    "   a. Variable nodes send their current values to connected check nodes.\n",
    "   b. Check nodes compute and send messages back to variable nodes.\n",
    "   c. Variable nodes update their values based on received messages and a threshold rule.\n",
    "3. Repeat until a valid codeword is found or maximum iterations are reached.\n",
    "\n",
    "#### Implementation:\n",
    "\n",
    "Our implementation includes two main functions:\n",
    "\n",
    "1. `gallager_b_algorithm(H, error_pattern, max_iterations=100)`:\n",
    "   - Implements the Gallager B decoding algorithm.\n",
    "   - Uses thresholds th0 = th1 = 0.5 for bit value updates.\n",
    "   - Returns True if decoding is successful (all bits become zero), False otherwise.\n",
    "\n",
    "2. `find_least_weight_error_pattern(H, code_distance)`:\n",
    "   - Searches for the least weight error pattern that Gallager B fails to correct.\n",
    "   - Starts from weight 1 and increases up to the code distance.\n",
    "\n",
    "#### Code Explanation:\n",
    "\n",
    "- We initialize the algorithm with the error pattern as the received vector.\n",
    "- In each iteration, we compute messages from variable nodes to check nodes.\n",
    "- We use numpy operations for efficient message computation and bit value updates.\n",
    "- The algorithm stops if all bits become zero (successful decoding) or max iterations are reached.\n",
    "- We test error patterns of increasing weight to find the least weight pattern that causes decoding failure.\n",
    "\n",
    "#### Significance:\n",
    "\n",
    "1. Performance Evaluation: By finding the least weight error pattern that Gallager B fails to correct, we can assess the practical error-correcting capability of our LDPC code with this decoding algorithm.\n",
    "\n",
    "2. Comparison with Code Distance: Comparing the least weight of uncorrectable errors with the code distance gives insights into the efficiency of Gallager B decoding for our specific code.\n",
    "\n",
    "3. Decoder Limitations: This analysis helps understand the limitations of the Gallager B algorithm and where it might fail in error correction.\n",
    "\n",
    "By implementing and analyzing the Gallager B algorithm, we gain practical insights into the performance of our LDPC code and the effectiveness of this decoding method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def gallager_b_algorithm(H, error_pattern, max_iterations=100):\n",
    "    n = H.shape[1]\n",
    "    m = H.shape[0]\n",
    "    x = np.array(error_pattern)\n",
    "    th0 = th1 = 0.5\n",
    "\n",
    "    for _ in range(max_iterations):\n",
    "        # Step 1: Initialize messages\n",
    "        messages = np.zeros((m, n))\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                if H[i, j] == 1:\n",
    "                    messages[i, j] = x[j]\n",
    "\n",
    "        # Step 2-5: Update messages and bit values\n",
    "        for j in range(n):\n",
    "            ones_count = np.sum(messages[:, j] == 1)\n",
    "            zeros_count = np.sum(messages[:, j] == 0)\n",
    "            total_count = ones_count + zeros_count\n",
    "\n",
    "            if zeros_count >= th0 * total_count:\n",
    "                x[j] = 0\n",
    "            elif ones_count >= th1 * total_count:\n",
    "                x[j] = 1\n",
    "\n",
    "        # Check if all bits are zero (decoding successful)\n",
    "        if np.all(x == 0):\n",
    "            return True\n",
    "\n",
    "    return False  # Decoding failed\n",
    "\n",
    "def find_least_weight_error_pattern(H, code_distance):\n",
    "    n = H.shape[1]\n",
    "    for weight in range(1, code_distance):\n",
    "        for error_pattern in itertools.combinations(range(n), weight):\n",
    "            error_vector = np.zeros(n, dtype=int)\n",
    "            error_vector[list(error_pattern)] = 1\n",
    "            if not gallager_b_algorithm(H, error_vector):\n",
    "                return weight, error_vector\n",
    "    return None, None\n",
    "\n",
    "# Use the H matrix we generated earlier\n",
    "code_distance = determine_code_distance(H)\n",
    "least_weight, error_pattern = find_least_weight_error_pattern(H, code_distance)\n",
    "\n",
    "print(f\"Code distance: {code_distance}\")\n",
    "if least_weight:\n",
    "    print(f\"Least weight error pattern that Gallager B fails to correct: {least_weight}\")\n",
    "    print(f\"Error pattern: {error_pattern}\")\n",
    "else:\n",
    "    print(\"Gallager B successfully corrects all error patterns up to the code distance.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
